{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punjabi Song Generation\n",
    "\n",
    "We are going to create a chatbot for generating Punjabi songs across different genres in the writing style of late Sidhu Moose Wala.\n",
    "<br>\n",
    "### Step 1: Understanding the Basics of the concepts used in the project\n",
    "Before we dive into the project, let's cover some fundamental concepts:\n",
    "<ul>\n",
    "<li>Language Models (LMs): These are AI models trained on large amounts of text data to understand and generate human-like text.\n",
    "<li>Transformers: A type of neural network architecture that's particularly effective for natural language processing tasks.\n",
    "<li>Fine-tuning: The process of further training a pre-trained model on a specific dataset to adapt it to a particular task.\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries\n",
    "install the required libraries using requirements.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shagundeepsingh/opt/anaconda3/envs/pytorch_lyrics/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Basic Python Libraries\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# evaluation\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# app creation\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Selecting an Initial Model\n",
    "\n",
    "Finding a model is tricky because of the limited resources as of me doing this project on M2 chip Macbook. Would have used gpt2 and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# At the start of your script, set the device\n",
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer\n",
    "    \n",
    "model_name = \"gpt2\" # have to find a suitable model because of limited resources\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Collection and Preparation\n",
    "\n",
    "We have to create a selenium bot to webscrape data from a public lyrics website I found\n",
    "<br>\n",
    "Let's start by scraping the links of the songs and then we can focus on collecting the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# The target website\n",
    "url = \"https://www.azlyrics.com/s/sidhumoosewala.html\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "try:\n",
    "    # Wait for the element to be clickable\n",
    "    sort_by_song_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"/html/body/div[2]/div[2]/div[2]/a[2]\"))\n",
    "    )\n",
    "    # Scroll to the element\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView();\", sort_by_song_button)\n",
    "    sort_by_song_button.click()\n",
    "\n",
    "except ElementClickInterceptedException:\n",
    "    # Handle overlay or pop-up\n",
    "    close_button = driver.find_element(By.XPATH, \"/html/body/div[5]/tonefuse-ad/div[2]/div[1]\")\n",
    "    close_button.click()\n",
    "    sort_by_song_button.click()\n",
    "\n",
    "# Wait for the page to re-load after sorting\n",
    "time.sleep(2)\n",
    "\n",
    "# Find all song links\n",
    "song_links = driver.find_elements(By.CSS_SELECTOR, \"div.listalbum-item a\")\n",
    "\n",
    "# List to store song data\n",
    "songs_data = []\n",
    "\n",
    "for link in song_links:\n",
    "    song_url = link.get_attribute(\"href\")\n",
    "    song_title = link.text\n",
    "    songs_data.append({\n",
    "        \"title\": song_title,\n",
    "        \"url\": song_url\n",
    "    })\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df = pd.DataFrame(songs_data)\n",
    "df.to_csv(\"song_links.csv\", index=False)\n",
    "\n",
    "print(f\"Collected {len(songs_data)} song links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "driver.set_page_load_timeout(30)  # Increased timeout to 30 seconds\n",
    "\n",
    "# Read the CSV file with song links\n",
    "df = pd.read_csv(\"sidhu_moose_wala_song_links.csv\")\n",
    "\n",
    "# List to store scraped data\n",
    "songs_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    song_title = row['title']\n",
    "    song_url = row['url']\n",
    "    \n",
    "    logging.info(f\"Scraping: {song_title}\")\n",
    "    \n",
    "    for attempt in range(3):  # Retry up to 3 times\n",
    "        try:\n",
    "            driver.get(song_url)\n",
    "            \n",
    "            # Wait for the lyrics to load\n",
    "            lyrics_div = WebDriverWait(driver, 30).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div[2]/div[2]/div[5]\")) \n",
    "            )\n",
    "            \n",
    "            # Extract lyrics\n",
    "            lyrics = lyrics_div.text.strip()\n",
    "            \n",
    "            if lyrics:\n",
    "                songs_data.append({\n",
    "                    \"title\": song_title,\n",
    "                    \"artist\": \"Sidhu Moose Wala\",\n",
    "                    \"lyrics\": lyrics,\n",
    "                    \"genre\": \"Punjabi\",\n",
    "                    \"url\": song_url\n",
    "                })\n",
    "                logging.info(f\"Successfully scraped lyrics for {song_title}\")\n",
    "                break  # Exit the retry loop on success\n",
    "            else:\n",
    "                logging.warning(f\"Could not find lyrics for {song_title}\")\n",
    "                break  # Exit the retry loop if lyrics are empty\n",
    "        \n",
    "        except (TimeoutException, NoSuchElementException) as e:\n",
    "            logging.error(f\"Error scraping {song_title} on attempt {attempt + 1}: {str(e)}\")\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "    \n",
    "    # Random delay between 2 to 5 seconds\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "df_lyrics = pd.DataFrame(songs_data)\n",
    "df_lyrics.to_csv(\"sidhu_moose_wala_songs_with_lyrics.csv\", index=False)\n",
    "\n",
    "logging.info(f\"Scraped lyrics for {len(songs_data)} songs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the next steps we can take:\n",
    "<ol>\n",
    "\n",
    "<li>Data Preprocessing\n",
    "<li>Tokenization\n",
    "<li>Model Selection and Fine-tuning\n",
    "<li>Implementing Retrieval-Augmented Generation (RAG)\n",
    "<li>Building the Generation Pipeline\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_lyrics(text):\n",
    "    # Remove any [tags] often used for annotations\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # Remove any parentheses and their contents\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Remove any non-printable characters\n",
    "    text = ''.join(char for char in text if char.isprintable())\n",
    "    return text\n",
    "\n",
    "# apply cleaning\n",
    "df_lyrics['cleaned_lyrics'] = df_lyrics['lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.lyrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_lyrics.copy()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total songs: {len(df1)}\")\n",
    "print(f\"Average lyrics length: {df1['cleaned_lyrics'].str.len().mean():.2f} characters\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(text):\n",
    "    return tokenizer.encode(text, truncation=True, max_length=512)\n",
    "\n",
    "# apply tokenization\n",
    "df1['tokenized_lyrics'] = df1['cleaned_lyrics'].apply(tokenize_lyrics)\n",
    "\n",
    "print(f\"Average token length: {df1['tokenized_lyrics'].apply(len).mean():.2f}\")\n",
    "\n",
    "print(\"\\nSample of tokenized lyrics:\")\n",
    "print(df1['tokenized_lyrics'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "df1.to_csv(\"cleaned_sidhu_moose_wala_songs.csv\", index=False)\n",
    "df1.to_pickle(\"tokenized_sidhu_moose_wala_songs.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fine-Tuning model\n",
    "\n",
    "As I am doing this project on a Apple M2 Chip, it would be better to do a PEFT rather than full fine tuning.\n",
    "\n",
    "Using Parameter-Efficient Fine-Tuning (PEFT) techniques like LoRA (Low-Rank Adaptation) is indeed a better approach for our task. It's more efficient in terms of computational resources and storage, and it can often lead to better results, especially with smaller datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from the pickle file (if needed, otherwise use df1)\n",
    "df2 = pd.read_pickle('tokenized_sidhu_moose_wala_songs.pkl')\n",
    "df2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make dataset proper for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[['cleaned_lyrics', 'tokenized_lyrics']]\n",
    "\n",
    "# create a dataset object\n",
    "dataset = Dataset.from_pandas(df2)\n",
    "\n",
    "# prepare dataset for language modeling\n",
    "def prepare_train_features(examples):\n",
    "    inputs = tokenizer(examples['cleaned_lyrics'], truncation=True, padding='max_length', max_length=512)\n",
    "    inputs['labels'] = inputs['input_ids'].copy()\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(prepare_train_features, batched=True, remove_columns=['cleaned_lyrics','tokenized_lyrics'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the lora config\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['query','value']\n",
    ")\n",
    "\n",
    "# wrap the model with LoRA\n",
    "model = get_peft_model(model, peft_config=peft_config)\n",
    "\n",
    "# set up data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using  data collator, we simplify our data preparation process and ensure that our model receives properly formatted input during training, which is crucial for effective learning and generation of song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS built: {torch.backends.mps.is_built()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "# i've used chatgpt to set up initial training params based on apple M2 chip\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=2,  \n",
    "    per_device_train_batch_size=4,  # Reduced from 8 to 4 to avoid potential memory issues\n",
    "    gradient_accumulation_steps=8,  # Increased from 4 to 8 to maintain effective batch size\n",
    "    save_steps=50,  # Reduced from 500 to 50 because of smaller dataset\n",
    "    save_total_limit=2,\n",
    "    learning_rate=1e-4,  # Slightly increased from 5e-5 for potentially faster learning\n",
    "    warmup_steps=10,  # Reduced from 100 due to smaller dataset\n",
    "    logging_steps=10,  # Reduced from 50 for more frequent updates\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,  # Reduced from 500 to match save_steps\n",
    "    load_best_model_at_end=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=False,  # MPS doesn't support fp16\n",
    "    bf16=False,  # MPS doesn't support bf16\n",
    "    report_to=\"none\",\n",
    "    no_cuda=True,  # This ensures CUDA is not used\n",
    "    weight_decay=0.01,  # Added weight decay for regularization\n",
    "    max_grad_norm=1.0,  # Gradient clipping to prevent exploding gradients\n",
    "    lr_scheduler_type=\"cosine\",  # Cosine learning rate scheduler for potentially better convergence\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the LoRA adapter\n",
    "model.save_pretrained(\"./sidhu_lyrics_lora_adapter\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "song_model = AutoModelForCausalLM.from_pretrained(\"sidhu_lyrics_lora_adapter\")\n",
    "song_tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=song_model, tokenizer=song_tokenizer, device=device)\n",
    "\n",
    "def generate_lyrics(prompt):\n",
    "    generated = generator(\n",
    "        prompt, \n",
    "        max_length=1000, \n",
    "        num_return_sequences=1, \n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "    return generated[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample prompt\n",
    "prompt = \"sardari di ae gal\" \n",
    "generated_lyrics = generate_lyrics(prompt)\n",
    "\n",
    "print(generated_lyrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output does not makes any sense.\n",
    "\n",
    "Lets try prompt engineering with one shot inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with one-shot prompting\n",
    "example_prompt = \"\"\"\n",
    "Title: 8 Cylinder\n",
    "Lyrics:Engine 8 cylinder da\n",
    "Dharti patda phire mutiyare\n",
    "\n",
    "Sidhu Moose Wala!\n",
    "\n",
    "68 model Shelby ni\n",
    "Tere layi billo ajj chamkati\n",
    "Hydraulic pava de ni\n",
    "Infinity di bass rakhati\n",
    "Ho kala rang hai sapp warga (haye haye)\n",
    "Kala rang hai sapp warga\n",
    "Ho kive dekh maare lishkare\n",
    "\n",
    "Engine 8 cylinder da\n",
    "Dharti patda phire mutiyare\n",
    "Haan karde gabru nu\n",
    "Tere magar gehdiyan maare\n",
    "\n",
    "Zor la leya duniya ne\n",
    "Haye jatt rokeya kade na rukda\n",
    "Moosa pind support kare\n",
    "Te meri pitth te Brampton pugda\n",
    "Baaki puch layi lokan to\n",
    "Baaki puch layi lokan to\n",
    "Tu Sidhu Moose Wale baare\n",
    "\n",
    "Engine 8 cylinder da\n",
    "Dharti patda phire mutiyare\n",
    "Haan karde gabru nu\n",
    "\n",
    "Title: sardari di ae gal\n",
    "Lyrics:\"\"\"\n",
    "\n",
    "generated_lyrics = generate_lyrics(example_prompt)\n",
    "print(generated_lyrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
